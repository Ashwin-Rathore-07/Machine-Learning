{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08038d8b-e964-4984-b3d6-a6541893b095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8228105906313645\n",
      "Test Accuracy: 0.7886178861788617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7886178861788617"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Load dataset\n",
    "df = pd.read_csv(\"loan.csv\")\n",
    "\n",
    "# Target variable\n",
    "y = df[\"Loan_Status\"]\n",
    "X = df.drop(columns=[\"Loan_Status\"])\n",
    "\n",
    "# Encode target (Loan_Status: Y/N)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# =========================\n",
    "# Step 1: Missing Value Imputation (trf1)\n",
    "# =========================\n",
    "num_cols = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "cat_cols = X_train.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "trf1 = ColumnTransformer([\n",
    "    (\"num_imputer\", num_imputer, num_cols),\n",
    "    (\"cat_imputer\", cat_imputer, cat_cols)\n",
    "], remainder=\"passthrough\")\n",
    "\n",
    "# =========================\n",
    "# Step 2: Feature Construction (trf2)\n",
    "# =========================\n",
    "def feature_construction(X):\n",
    "    # Convert to DataFrame with proper column names\n",
    "    df = pd.DataFrame(X, columns=num_cols.tolist() + cat_cols.tolist())\n",
    "    \n",
    "    # Ensure numeric columns are floats\n",
    "    for col in [\"LoanAmount\", \"ApplicantIncome\", \"CoapplicantIncome\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Create new features\n",
    "    if \"LoanAmount\" in df.columns:\n",
    "        df[\"LoanAmount_log\"] = np.log1p(df[\"LoanAmount\"].fillna(0))\n",
    "    if \"ApplicantIncome\" in df.columns:\n",
    "        df[\"TotalIncome\"] = df[\"ApplicantIncome\"] + df.get(\"CoapplicantIncome\", 0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "trf2 = FunctionTransformer(feature_construction, validate=False)\n",
    "\n",
    "# =========================\n",
    "# Step 3: Handle Categorical Features (OneHotEncoding) (trf3)\n",
    "# =========================\n",
    "one_hot = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "trf3 = ColumnTransformer([\n",
    "    (\"onehot\", one_hot, cat_cols)\n",
    "], remainder=\"passthrough\")\n",
    "\n",
    "# =========================\n",
    "# Step 4: Scaling (trf4)\n",
    "# =========================\n",
    "trf4 = StandardScaler()\n",
    "\n",
    "# =========================\n",
    "# Step 5: Feature Selection (trf5)\n",
    "# =========================\n",
    "trf5 = SelectKBest(score_func=f_classif, k=10)\n",
    "\n",
    "# =========================\n",
    "# Step 6: Model (trf6)\n",
    "# =========================\n",
    "trf6 = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# =========================\n",
    "# Pipeline\n",
    "# =========================\n",
    "pipe = Pipeline([\n",
    "    ('trf1', trf1),\n",
    "    ('trf2', trf2),\n",
    "    ('trf3', trf3),\n",
    "    ('trf4', trf4),\n",
    "    ('trf5', trf5),\n",
    "    ('trf6', trf6)\n",
    "])\n",
    "\n",
    "# Fit pipeline\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy\n",
    "print(\"Train Accuracy:\", pipe.score(X_train, y_train))\n",
    "print(\"Test Accuracy:\", pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ec7a848-8db4-46df-a991-465f9632a4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d665f80b-de53-44b6-9ced-5594ce404394",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pipe\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n\u001b[0;32m      2\u001b[0m x_train_transformed \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrf6\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "pipe.fit(x_train, y_train)\n",
    "x_train_transformed = pipe.named_steps['trf6'].transform(...)  # last transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db1a332e-203b-47d9-94a9-58751a5229b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender               13\n",
       "Married               3\n",
       "Dependents           15\n",
       "Education             0\n",
       "Self_Employed        32\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           22\n",
       "Loan_Amount_Term     14\n",
       "Credit_History       50\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62363a25-400f-4ba7-9756-4e3767e36e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
